# -*- coding: utf-8 -*-
"""ibin_cnnmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18TCFGjviOSupBCXIAWYvXEhh6GudbliO
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

import numpy as np
import os
import itertools
from tqdm import tqdm
from random import shuffle
import cv2
import imp
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU
from tensorflow.keras import optimizers
from tensorflow.keras.models import load_model

!unzip "drive/My Drive/TreeClassification/train.zip"

!unzip "drive/My Drive/TreeClassification/test.zip"

import sys
sys.path.append("drive/My Drive/TreeClassification")
import ibin_dataloader

IMG_SIZE = ibin_dataloader.IMG_SIZE

# CNN model
model = tf.keras.Sequential()

model.add(Conv2D(filters=16, kernel_size=3, padding='same', activation='sigmoid', input_shape=(IMG_SIZE, IMG_SIZE, 3)))
model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='sigmoid'))
model.add(MaxPooling2D(pool_size=2))

#model.add(Dropout(0.5))
model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='sigmoid'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.5))

# model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))
# model.add(MaxPooling2D(pool_size=2))

# model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='sigmoid'))
# model.add(MaxPooling2D(pool_size=2))

# model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='sigmoid'))
# model.add(MaxPooling2D(pool_size=2))

model.add(Flatten())

model.add(Dense(1024, activation='sigmoid'))
model.add(Dropout(0.5))

#model.add(Dense(128, activation='sigmoid'))
#model.add(Dropout(0.5))

model.add(Dense(ibin_dataloader.num_classes, activation='softmax'))

# Model summary
model.summary()

# Run the model
sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)

model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

hist = model.fit(ibin_dataloader.x_train, ibin_dataloader.y_train, batch_size=32, validation_split=0.1, shuffle=True, epochs=2)

# Get loss & accuracy
train_loss=hist.history['loss']
val_loss=hist.history['val_loss']
train_acc=hist.history['acc']
val_acc=hist.history['val_acc']

# Evaluate the model 
score = model.evaluate(ibin_dataloader.x_test, ibin_dataloader.y_test, batch_size=32)
print("%s: %.2f%%" % (model.metrics_names[1], score[1]*100))

#  Accuracy Plot
plt.plot(hist.history['acc'])
plt.plot(hist.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# Save the model
model.save('ibin_4classes.h5')

